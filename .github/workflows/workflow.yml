# .github/workflows/ci_cd.yml
name: CI/CD and Scheduled Retraining with DVC (Google Drive)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '*/60 * * * *' # Runs every 60 minutes for demonstration
  workflow_dispatch:

env:
  DOCKER_IMAGE_NAME: california-housing-api
  DOCKER_REGISTRY: docker.io

jobs:
  # This job is now faster as it only lints and runs tests that don't need data.
  lint-and-unit-test:
    if: github.event_name != 'schedule'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9]
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Cache and Install Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-cov flake8 black
    - name: Lint with flake8
      run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
    - name: Run unit tests
      run: pytest tests/ -v # Assuming tests that don't need the full dataset are here

  # DVC CHANGE: This new job combines all steps that need data.
  # It pulls data once and runs validation, testing, and checks.
  integration-test-with-data:
    if: github.event_name != 'schedule'
    runs-on: ubuntu-latest
    needs: lint-and-unit-test
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.9
    - name: Install dependencies including DVC
      # DVC CHANGE: Install DVC with Google Drive support
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install "dvc[gdrive]" pytest-cov

    - name: Authenticate to Google Drive
      # DVC CHANGE: Use secret to create credentials file for DVC
      run: echo '${{ secrets.GDRIVE_CREDENTIALS_DATA }}' > gdrive-credentials.json

    - name: Pull data from DVC remote
      # DVC CHANGE: Configure DVC and pull data from Google Drive
      run: |
        dvc remote modify gdriveremote gdrive_service_account_json_file_path gdrive-credentials.json
        dvc pull -r gdriveremote

    - name: Run all data-dependent scripts
      # DVC CHANGE: All data-related steps are now consolidated here
      run: |
        python src/data_preprocessing.py
        python scripts/train_models.py
        python scripts/validate_model.py
        python scripts/check_model_drift.py
        pytest tests/ -v --cov=src --cov-report=xml # Run full test suite with data

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: integration-tests
        name: codecov-umbrella

  # Your security scan job remains the same
  security-scan:
    if: github.event_name != 'schedule'
    runs-on: ubuntu-latest
    needs: lint-and-unit-test
    # ... (rest of security-scan job is unchanged)

  build-and-push:
    if: github.event_name != 'schedule' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    needs: integration-test-with-data
    steps:
    - uses: actions/checkout@v3

    # DVC CHANGE: Added steps to pull data before building the Docker image
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.9
    - name: Install DVC
      run: pip install "dvc[gdrive]"
    - name: Authenticate to Google Drive
      run: echo '${{ secrets.GDRIVE_CREDENTIALS_DATA }}' > gdrive-credentials.json
    - name: Pull data and models into build context
      run: |
        dvc remote modify gdriveremote gdrive_service_account_json_file_path gdrive-credentials.json
        dvc pull -r gdriveremote
    # End of DVC changes for this job

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    - name: Log in to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        file: ./dockerfile
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:latest,${{ secrets.DOCKER_USERNAME }}/${{ env.DOCKER_IMAGE_NAME }}:${{ github.sha }}
        labels: |
          org.opencontainers.image.source=${{ github.repositoryUrl }}
          org.opencontainers.image.revision=${{ github.sha }}

  # Deploy job is unchanged
  deploy:
    if: github.event_name != 'schedule' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    needs: build-and-push
    # ... (rest of deploy job is unchanged)

  # =================================================================
  # === UPDATED JOB FOR AUTOMATED RETRAINING WITH DVC =============
  # =================================================================
  auto-retrain-and-commit:
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.PAT }} # PAT is needed to push commits

      - name: Set up Python and DVC
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install "dvc[gdrive]"

      - name: Authenticate to Google Drive
        run: echo '${{ secrets.GDRIVE_CREDENTIALS_DATA }}' > gdrive-credentials.json

      - name: Pull existing data and model
        run: |
          dvc remote modify gdriveremote gdrive_service_account_json_file_path gdrive-credentials.json
          dvc pull -r gdriveremote

      - name: Check for retraining and execute
        id: retrain_check
        run: |
          python -c "
          from scripts.auto_train import AutoRetrainer;
          retrainer = AutoRetrainer();
          if retrainer.check_retrain_conditions():
              print('Retraining conditions met. Starting model retraining.')
              retrainer.retrain_model()
              print('::set-output name=retrained::true')
          else:
              print('Retraining conditions not met. No action needed.')
              print('::set-output name=retrained::false')
          "

      - name: Push new model to DVC and commit pointer file
        if: steps.retrain_check.outputs.retrained == 'true'
        run: |
          # DVC CHANGE: Track changes to the models and data directories
          dvc add models data

          # DVC CHANGE: Push the actual file contents to Google Drive
          dvc push -r gdriveremote

          # DVC CHANGE: Commit the updated pointer files (*.dvc) to Git
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add models.dvc data.dvc

          if ! git diff --staged --quiet; then
            git commit -m "chore(bot): auto-retrain and update model/data"
            git push
            echo "New model/data version pushed to DVC and pointers committed to Git."
          else
            echo "Model was retrained, but no changes were detected in the final files."
          fi